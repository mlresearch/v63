<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Geometry-aware stationary subspace analysis | ACML 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Geometry-aware stationary subspace analysis">

  <meta name="citation_author" content="Horev, Inbal">

  <meta name="citation_author" content="Yger, Florian">

  <meta name="citation_author" content="Sugiyama, Masashi">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of The 8th Asian Conference on Machine Learning">
<meta name="citation_firstpage" content="430">
<meta name="citation_lastpage" content="444">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v63/Horev84.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Geometry-aware stationary subspace analysis</h1>

	<div id="authors">
	
		Inbal Horev,
	
		Florian Yger,
	
		Masashi Sugiyama
	<br />
	</div>
	<div id="info">
		Proceedings of The 8th Asian Conference on Machine Learning,
		pp. 430–444, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		In many real-world applications data exhibits non-stationarity, i.e., its distribution changes over time.  One approach to handling non-stationarity is to remove or minimize it before attempting to analyze the data.  In the context of brain computer interface (BCI) data analysis this is sometimes achieved using stationary subspace analysis (SSA).  The classic SSA method finds a matrix that projects the data onto a stationary subspace by optimizing a cost function based on a matrix divergence.  In this work we present an alternative method for SSA based on a symmetrized version of this matrix divergence.  We show that this frames the problem in terms of distances between symmetric positive definite (SPD) matrices, suggesting a geometric interpretation of the problem.  Stemming from this geometric viewpoint, we introduce and analyze a method which utilizes the geometry of the SPD matrix manifold and the invariance properties of its metrics.  Most notably we show that these invariances alleviate the need to whiten the input matrices, a common step in many SSA methods which often introduces error.  We demonstrate the usefulness of our technique in experiments on both synthetic and real-world data.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="Horev84.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
